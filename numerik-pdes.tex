\documentclass{cheat-sheet}

\pdfinfo{
  /Title (Zusammenfassung Numerik von partiellen Differentialgleichungen)
  /Author (Tim Baumann)
}

\usepackage{nicefrac}

% Kleinere Klammern
\delimiterfactor=701

\newcommand{\Cont}{\mathcal{C}} % Menge der stetigen/diff'baren Funktionen
\newcommand{\clos}[1]{\overline{#1}} % topologischer Abschluss
\newcommand{\cOmega}{\clos{\Omega}} % weil's so häufig gebraucht wird
\newcommand{\bOmega}{\partial \Omega} % weil's so häufig gebraucht wird
\newcommand{\LL}{\mathcal{L}} % Lösungsoperator
\newcommand{\RR}{\mathcal{R}} % Randoperator
\newcommand{\Laplace}{\Delta}
\DeclareMathOperator{\dive}{div} % Divergenz
\newcommand{\tss}[1]{\textsubscript{#1}} % Subskript, kürzer
\newcommand{\rn}{\text{rn}} % randnah
\newcommand{\rf}{\text{rf}} % randfern

\begin{document}

\maketitle{Zusammenfassung Numerik von PDEs}

% Vorlesung vom 13. Oktober 2015

% 1. Einführung

% Ausgelassen: Notationen

% 1.1. Klassifikation von partiellen DGLn

\begin{defn}
  Sei $\Omega \subseteq \R^n$ offen.
  Eine DGL der Form
  \[ F(x, u, Du, \ldots, D^k u) = 0 \]
  heißt \emph{partielle DGL/PDE} der Ordnung $k \geq 1$, wobei
  \[ F : \Omega \times \R \times \R^n \times \ldots \times \R^{n^k} \to \R \]
  eine gegebene Funktion und $u : \Omega \to \R$ gesucht ist.
\end{defn}

\begin{defn}[\emph{Klassifikation von PDEs}]\mbox{}\\
  \begin{itemize}
    \item Die PDE heißt \emph{linear}, wenn sie die Form
    \[ \sum_{\abs{\alpha} \leq k} a_\alpha(x) D^\alpha u = f(x) \]
    mit Funktionen $a_\alpha, f : \Omega \to \R$ besitzt.
    \item Die PDE heißt \emph{semilinear}, wenn sie die Form
    \[ \sum_{\abs{\alpha} = k} a_\alpha(x) D^\alpha u + a_0(x, u, D_u, \ldots, D^{k-1} u) = 0 \]
    besitzt, wobei $a_\alpha : \Omega \to \R$ und $a_0 : \Omega \times \R \times \R^n \times \ldots \times \R^{n^k} \to \R$ gegeben sind.
    \item Die PDE heißt \emph{quasilinear}, wenn sie die Form
    \[ \sum_{\abs{\alpha} = k} a_\alpha(x, u, Du, \ldots, D^{k-1} u) D^\alpha u + a_0(x, u, D_u, \ldots, D^{k-1} u) = 0 \]
    hat, wobei $a_\alpha, a_0 : \Omega \times \R \times \R^n \times \ldots \times \R^{n^k}$ gegeben sind.
    \item Die PDE heißt \emph{nichtlinear}, falls die Ableitungen der höchsten Ordnung nicht linear vorkommen.
  \end{itemize}
\end{defn}

% Ausgelassen: Beispiele: Poisson-, Laplace-, Wärmeleitungs-, Wellengleichung sowie Navier-Stokes-Gleichung

\begin{defn}
  Sei $\Omega \subseteq \R^n$ offen und $F : \Omega \times \R \times \R^n \times \R^{n \times n} \to \R$ eine gegebene Funktion.
  Eine PDE der Form
  \[ F(x, u, \partial_{x_1} u, \ldots, \partial_{x_n} u, \partial_{x_1} \partial_{x_1} u, \ldots, \partial{x_1} \partial_{x_n} u, \ldots, \partial_{x_n} \partial_{x_n} u) = 0 \]
  heißt \emph{PDE zweiter Ordnung}.
\end{defn}

\begin{nota}
  $p_i \coloneqq \partial_{x_i} u$, $p_{ij} \coloneqq \partial^2_{x_i x_j} u$
  \[
    M(x) \coloneqq \begin{pmatrix}
      \tfrac{\partial F}{\partial p_{11}} & \hdots & \tfrac{\partial F}{\partial p_{1n}} \\
      \vdots && \vdots \\
      \tfrac{\partial F}{\partial p_{n1}} & \hdots & \tfrac{\partial F}{\partial p_{nn}}
    \end{pmatrix} = M(x)^{T}.
  \]
\end{nota}

\begin{defn}[\emph{Typeneinteilung für PDEs der 2. Ordnung}]\mbox{}\\
  Obige PDE zweiter Ordnung heißt
  \begin{itemize}
    \item \emph{elliptisch} in $x$, falls die Matrix $M(x)$ positiv o. definit ist.
    \item \emph{parabolisch} in $x$, falls genau ein EW von $M(x)$ gleich null ist und alle anderen dasselbe Vorzeichen haben.
    \item \emph{hyperbolisch} in $x$, falls genau ein EW ein anderes Vorzeichen als die anderen EWe hat.
  \end{itemize}
\end{defn}

% Ausgelassen: Beispiele

% Vorlesung vom 19. Oktober 2015

% 2. Klassische Lösungstheorie für elliptische PDEs
\section{Lösungstheorie elliptischer PDEs}

\begin{defn}
  Sei $\Omega \subset \R^n$ offen, zusammenhängend und beschränkt.
  \begin{itemize}
    \item $\Cont(\cOmega, \R^m) \coloneqq \Set{u : \cOmega \to \R^m}{u \text{ stetig}}$, $\Cont(\cOmega) \coloneqq \Cont(\cOmega, \R)$, mit Norm
    \[
      \norm{u}_{\Cont(\cOmega, \R^m)} = \sup_{x \in \cOmega} \norm{u(x)}.
      \tag{Supremumsnorm}
    \]
    \item $\Cont^k(\cOmega, \R^m)$, $k \in \N$ ist der Raum aller auf $\Omega$ $k$-mal stetig diff'baren Funktionen $u : \Omega \to \R^m$, die zusammen mit ihren Ableitungen bis zur Ordnung $k$ stetig auf $\cOmega$ fortgesetzt werden können.
    \[ \norm{u}_{\Cont^k(\overline{\Omega}, \R^m)} = \sum_{\abs{\alpha} \leq k} \norm{D^\alpha u}_{\Cont(\overline{\Omega}, \R^m)} \]
    \item Sei $\alpha \in \cointerval{0}{1}$. $\Cont^{0,\alpha}(\cOmega, \R^m) = \Set{u \in \Cont(\cOmega, \R^m)}{H_\alpha(u, \cOmega) < \infty}$ mit
    \[
      H_\alpha(u, \cOmega) \coloneqq \sup_{x, y \in \cOmega, x \neq y} \tfrac{\norm{u(x)-u(y)}}{\norm{x-y}^\alpha}
      \tag{Hölder-Koeffizient}
    \]
    heißt \emph{Raum der glm. Hölder-stetigen Fktn} zum Exponent $\alpha$.
    Der Hölder-Koeffizient ist dabei eine Seminorm auf $\Cont^{0,\alpha}(\cOmega, \R^m)$.
    \item $\Cont^{k,\alpha}(\cOmega, \R^m) \coloneqq \Set{u \in \Cont^k(\cOmega, \R^m)}{\fa{\abs{\gamma} = k} D^\gamma u \in \Cont^{0, \alpha}(\cOmega, \R^m)}$ heißt \emph{Hölder-Raum}.
    Eine Norm ist gegeben durch
    \[ \norm{u}_{\Cont^{k,\alpha}(\cOmega, \R^m)} \coloneqq \norm{u}_{\Cont^k(\cOmega, \R^m)} + \sum_{\abs{\gamma} = k} H_\alpha(D^\gamma u, \cOmega). \]
  \end{itemize}
\end{defn}

\begin{bem}
  \begin{itemize}
    \item Jede Hölder-stetige Funktion ist gleichmäßig stetig.
    \item $\Cont^{0,1}(\cOmega, \R^m)$ heißt \emph{Raum der Lipschitz-stetigen Funktionen}.
    \item $\Cont$, $\Cont^k$ und $\Cont^{k,\alpha}$ sind Banach-Räume mit den jeweiligen Normen.
  \end{itemize}
\end{bem}

\iffalse
\begin{bsp}
  Betrachte $u(x) = \abs{x}^\beta$ auf $\ointerval{-1}{1} = \Omega$. Dann ist
  \[ \tfrac{\abs{u(x) - u(0)}}{\abs{x - 0}^\alpha} = \abs{X}^{\beta - \alpha} \]
  genau dann beschränkt, falls $\beta \geq \alpha$.
  In diesem Fall ist $u$ Hölder-stetig zum Exponent $\alpha$.
\end{bsp}
\fi

\begin{defn}
  Sei $\Omega \subset \R^n$ offen, zusammenhängend und beschränkt. \\
  Das Gebiet $\Omega$ gehört zur \emph{Klasse $\Cont^{k,\alpha}$}, wenn in jedem Punkt $x \in \bOmega$ eine Umgebung in $\bOmega$ existiert, die sich in einem geeigneten Koordinatensystem als ein Graph einer Funktion aus $\Cont^{k,\alpha}$ darstellen lässt und $\Omega$ lokal immer auf einer Seite von $\bOmega$ liegt.
\end{defn}

% Ausgelassen: Beispiele und Gegenbeispiele von Gebieten aus $\Cont^{k,\alpha}$

\begin{satz}[\emph{Gauß'scher Integralsatz}]
  Sei $\Omega \subset \R^n$ ein Lipschitz-Gebiet und $u \in \Cont(\cOmega, \R^n) \cap \Cont^1(\Omega, \R^n)$.
  Dann gilt
  \[ \Int{\Omega}{}{\dive u}{x} = \Int{\Omega}{}{\sum_{i=1}^n \tfrac{\partial u_i}{\partial x_i}}{x} = \Int{\bOmega}{}{\sum_{i=1}^n u_i \nu_i}{\rho(x)} = \Int{\bOmega}{}{u \cdot \nu}{\rho(x)}, \]
  wobei $\nu$ der äußere Normalenvektor an an den Rand von $\Omega$ ist.
\end{satz}

\begin{prob}
  Wir betrachten das Randwertproblem
  \[
    \text{(RWP)} \left\{ \begin{array}{rllll}
      \LL u &=& f &\text{ in $\Omega$} & \text{(PDE)} \\
      \RR u &=& g &\text{ auf $\bOmega$} & \text{(Randbedingung)}
    \end{array} \right.
  \]
  wobei $\LL$ der lineare Differentialoperator
  \[
    \LL u = - \sum_{i,j=1}^n a_{ij}(x) \tfrac{\partial^2 u}{\partial x_i \partial x_j} + \sum_{i=1}^n b_i(x) \tfrac{\partial u}{\partial x_i} + c(x) u
  \]
  mit Fktn $a_{ij}, b_i, c, f : \Omega \to \R$, $g : \bOmega \to \R$ ist, sodass $A(x) \coloneqq (a_{ij}(x))$ symmetrisch ist.
  Als Randbedingung (RB) verlangen wir:
  \[ \begin{array}{rllll}
    \text{\emph{Dirichlet-RB}:} & u &=& g & \text{auf $\bOmega$,} \\
    \text{\emph{Neumann-RB}:} & (A(x) \nabla u) \cdot \nu &=& g & \text{auf $\bOmega$ oder} \\
    \text{\emph{Robin-RB}:} & (A(x) \nabla u) \cdot \nu + \delta u &=& g & \text{auf $\bOmega$.}
  \end{array} \]
\end{prob}

\begin{bem}
  Man kann auch auf verschiedenen Teilstücken des Randes verschiedene Bedingungen stellen.
\end{bem}

\begin{bem}
  Falls die Funktionen $a_{ij}$ differenzierbar sind, so kann $\LL$ in \emph{Divergenzform} geschrieben werden:
  \begin{align*}
    %\LL u & = - \sum_{i,j=1}^n a_{ij}(x) \tfrac{\partial^2 u}{\partial x_i \partial x_j} + \sum_{i=1}^n b_i(x) \tfrac{\partial u}{\partial x_i} + c(x) u  \\
    %& = - \sum_{i,j=1}^n \left( \tfrac{\partial}{\partial x_j} \left( a_{ij}(x) \tfrac{\partial u}{\partial x_i} \right) - \left( \tfrac{\partial}{\partial x_j} a_{ij}(x) \right) \tfrac{\partial u}{\partial x_i} \right) + \sum_{i=1}^n b_i(x) \tfrac{\partial u}{\partial x_i} + c(x) u \\
    \LL u & = - \!\!\! \sum_{i,j=1}^n \tfrac{\partial}{\partial x_j} \left( a_{ij}(x) \tfrac{\partial u}{\partial x_i} \right) \!+\! \sum_{i=1}^n \underbrace{\left((\sum_{j=1}^n \tfrac{\partial}{\partial x_j} a_{ij}(x) ) \!+\! b_i(x)\right)}_{\tilde{b}(x) \coloneqq} \tfrac{\partial u}{\partial x_i} \!+\! c(x) u \\
    & = - \dive(A(x) \nabla u) + \tilde{b}(x) \cdot \nabla u + c(x) u
  \end{align*}
\end{bem}
% TODO: \tilde{b}_i(x) ist der Term in Klammern im mittleren Term

\begin{voraussetzung}
  Wir nehmen im Folgenden an:
  \begin{itemize}
    \item $\LL$ ist \emph{gleichmäßig elliptisch}, \dh{}
    \[ \ex{\lambda_0 > 0} \fa{\xi \in \R^n} \fa{x \in \Omega} \xi^T A(x) \xi \geq \lambda_0 \norm{\xi}^2 \]
    Dabei heißt $\lambda_0$ \emph{Elliptizitätskonstante}.
    \item $a_{ij}, b_i, c, f \in \Cont(\cOmega)$, $g \in \Cont(\bOmega)$
  \end{itemize}
\end{voraussetzung}

\begin{bem}
  $\LL = f$ ist elliptisch auf $\Omega$ $\iff$ $A(x) > 0$ (spd) für alle $x \in \Omega$
\end{bem}

\begin{defn}
  Eine Fkt $u \in \Cont^2(\Omega) \cap \Cont(\cOmega)$ heißt \emph{klassische Lsg} vom (RWP) mit $\RR u \coloneqq u$, wenn die beiden Gleichungen in (RWP) in jedem Punkt von $\Omega$ bzw. des Randes $\bOmega$ erfüllt sind.
\end{defn}

% 2.1
\begin{satz}[\emph{Maximumsprinzip}]
  Sei $\Omega \subset \R^n$ offen, zshgd u. beschränkt.
  Sei $u \in \Cont^2(\omega) \cap \Cont(\cOmega)$ eine Lösung vom (RWP), $f \leq 0$ in $\Omega$ und $c \equiv 0$. \\
  Dann nimmt $u$ sein Maximum auf dem Rand $\bOmega$ an, \dh{}
  \[ \sup_{x \in \cOmega} u(x) = \sup_{x \in \bOmega} u(x) = \sup_{x \in \bOmega} g(x) \]
\end{satz}

% Vorlesung vom 20.10.2015

% 2.2
\begin{kor}
  Sei $c \geq 0$ und $f \leq 0$.
  Dann gilt
  $\sup_{x \in \cOmega} u(x) \leq \max \{ \sup_{x \in \bOmega} u(x), 0 \}$.
\end{kor}

% 2.3
\begin{kor}[\emph{Vergleichsprinzip}]
  Für $u_1, u_2 \in \Cont^2(\Omega) \cap \Cont(\cOmega)$ und $c \geq 0$ gelte $\LL u_1 \leq \LL u_2$ in $\Omega$ und $u_1 \leq u_2$ auf $\bOmega$.
  Dann gilt $u_1 \leq u_2$ auf $\cOmega$.
\end{kor}

% 2.4
\begin{kor}[Eindeutigkeit]
  Sei $c \geq 0$. Dann hat (RWP) höchstens eine Lösung $u \in \Cont^2(\Omega) \cap \Cont(\cOmega)$.
\end{kor}

\iffalse
\begin{bsp}
  Betrachte $-u'' - \lambda u = 0$ in $\Omega = \ointerval{0}{1}$ mit $\lambda > 0$, $u(0) = u(1) = 0$.
  \begin{itemize}
    \item $u \equiv 0$ ist eine Lösung
    \item Für $\lambda = k^2 \pi^2$ ist $u(x) = a \sin(k \pi x)$ auch eine Lösung
  \end{itemize}
\end{bsp}
\fi

% 2.5
\begin{satz}
  Sei $\Omega$ ein beschr. Lipschitz-Gebiet, $a_{ij}, b_i, c, f \in \Cont(\cOmega)$, $c \geq 0$, $g \in \Cont(\bOmega)$.
  Dann besitzt (RWP) genau eine Lsg $u \in \Cont^2(\Omega) \cap \Cont(\cOmega)$.
\end{satz}

% Beweis siehe J.H.Michael, "A general theory for linear elliptic partial differential equations", 1977

\begin{acht}
  Es muss aber nicht $u \in \Cont^2(\cOmega)$ gelten!
\end{acht}

\iffalse
\begin{bspe}
  \begin{itemize}
    \item $- \Laplace u = 0$ in $\ointerval{0}{1} \times \ointerval{0}{1}$, $u(0, x_2) = 0$, $u(1, x_2) = x_2$, $u(x_1, 0) = 0$, $u(x_1, 1) = x_1$ für $x_1, x_2 \in \cinterval{0}{1}$.
    Lösung: $u(x_1, x_2) = x_1 x_2$
    \item $- \Laplace u = 0$ in $\Omega = \ointerval{0}{1} \times \ointerval{0}{1}$,
    $u(x_1, x_2) = x_1^2$.
    Nach Satz 2.5 existiert eine Lösung $u \in \Cont^2(\Omega) \cap \Cont(\cOmega)$ aber $u \not\in \Cont^2(\cOmega)$, denn
    \[ \tfrac{\partial^2 u}{\partial x_1^2} + \tfrac{\partial^2 u}{\partial x_2^2} = 2 \neq 0 \]
    bei $x = (1, 1)$, auf $\bOmega$.
  \end{itemize}
\end{bspe}
\fi

% 3. Differenzenverfahren
\section{Differenzenverfahren}

% 3.1. Differenzenverfahren für die Poisson-Gleichung in $\Omega = \ointerval{0}{1}$

\begin{verf}[\emph{DV}]
  Am Beispiel des Poisson-Problems
  \[
    \text{(RWP\tss{1})}\enspace \left\{ \begin{array}{rl}
      - \Laplace u = f &\text{ in $\Omega = \ointerval{0}{1}$} \\
      u(0) = g_0, u(1) = g_1 &\text{ auf $\bOmega$}
    \end{array} \right.
  \]
  Wir führen folgende Schritte durch:
  \begin{enumerate}
    \item Diskretisierung: Wähle $n \in \N$, setze $h \coloneqq \tfrac{1}{n}$ und
    \begin{align*}
      \Omega_h &\coloneqq \Set{x_i \coloneqq ih}{i = 1, \ldots, n-1}
      \tag{innere Gitterpunkte} \\
      \partial \Omega_h &\coloneqq \{ x_0 = 0, x_n = 1 \}
      \tag{Randpunkte}
    \end{align*}
    \item Approx. der Ableitungen durch Differenzenquotienten (DQ)
    \begin{align*}
      u'(x_i) &\approx \tfrac{1}{h} \left(u(x_i + h) - u(x_i)\right)
      \tag{\emph{Vorwärts-DQ}} \\
      u'(x_i) &\approx \tfrac{1}{h} \left(u(x_i) - u(x_i - h)\right)
      \tag{\emph{Rückwärts-DQ}} \\
      u'(x_i) &\approx \tfrac{1}{2h} \left(u(x_i + h) - u(x_i - h)\right)
      \tag{\emph{zentraler DQ}}
    \end{align*}
    Für die zweite Ableitung ergibt sich
    \begin{align*}
      u''(x_i) &= (u'(x_i))' \approx \tfrac{1}{h} \left(u'(x_i + h) - u'(x_i)\right) \approx \\
      &\approx \tfrac{1}{h} \cdot \left(\tfrac{1}{h} \left( u(x_i + h) - u(x_i) \right) - \tfrac{1}{h} \left( u(x_i) - u(x_i - h) \right)\right) \\
      &= \tfrac{1}{h^2} \left( u(x_i + h) - 2 \cdot u(x_i) + u(x_i - h) \right) =: \Laplace_h u
    \end{align*}
    Dabei heißt $\Laplace_h$ der diskrete eindim. Laplace-Operator. \\
    Das diskretisierte Randwertproblem ist nun
    % TODO: Bezeichnung davon?
    \[
      \text{(RWP\tss{1})\tss{h}} \enspace
      \left\{ \begin{array}{rl}
        - \Laplace_h u_h = f &\text{ in $\Omega_h$,} \\
        u_h(0) = g_0, u_h(1) = g_1 &\text{ auf $\partial \Omega_h$.}
      \end{array} \right.
    \]
    \item Aufstellen des linearen Gleichungssystems
    \begin{align*}
      \tfrac{1}{h^2} \left( 2 u_h(x_1) - u_h(x_2) \right) &= f(x_1) + \tfrac{g_0}{h^2}
      \tag{$i\!=\!1$} \\
      \tfrac{1}{h^2} \left( -u_h(x_{i-1}) + u_h(x_i) - u_h(x_{i+1}) \right) &= f(x_i)
      \tag{$i=2, \nldots, n-2$} \\
      \tfrac{1}{h^2} \left( -u_h(x_{n-2}) + 2 u_h(x_{n-1}) \right) &= f(x_{n-1}) + \tfrac{g_1}{h^2}
      \tag{$i\!=\!n{-}1$}
    \end{align*}
    
    Als lineares Gleichungssystem: $- \tilde{\Laplace}_h \tilde{u}_h = \tilde{f}_h$ mit
    \[
      - \tilde{\Laplace}_h = \frac{1}{h^2} \begin{pmatrix}
        2 & -1 & &&& 0 \\
        -1 & 2 & -1 &&& \\
        & -1 & 2 & -1 && \\
        && \ddots & \ddots & \ddots \\
        &&& -1 & 2 & -1 \\
        0 &&&& -1 & 2
      \end{pmatrix} \in \R^{(n-1) \times (n-1)},
    \]
    \[
      \tilde{u}_h = \begin{pmatrix}
        u_h(x_1) \\ \vdots \\ u_h(x_{n-1})
      \end{pmatrix}, \quad
      \tilde{f}_h = \begin{pmatrix}
        f(x_1) + \tfrac{g_0}{h^2} \\
        f(x_2) \\
        \vdots \\
        f(x_{n-2}) \\
        f(x_{n-1}) + \tfrac{g_1}{h^2}
      \end{pmatrix}
    \]
  \end{enumerate}
\end{verf}

% Vorlesung vom 26.10.2015

% Konvergenz, Konsistenz, Stabilität

\begin{ziel}
  Herausfinden, was die Lösung~$u_h$ von (RWP)\tss{h} (die man durch Lösen von (LGS) erhält) mit der Lösung~$u$ zum ursprünglichen Problem (RWP) zu tun hat.
  Ist etwa~$u_h$ die Einschränkung von~$u$, oder zumindest annäherungsweise?
  Wenn ja, wie klein muss man~$h$ wählen, damit die Approximation gut wird?
  \begin{align*}
    \text{(RWP)} \enspace & \left\{ \begin{array}{rl}
      - \LL u = f &\text{ in $\Omega$,} \\
      u = g &\text{ auf $\partial \Omega$}
    \end{array} \right. \\
    \text{(RWP)\tss{h}} \enspace & \left\{ \begin{array}{rl}
      - \LL_h u = f_h &\text{ in $\Omega_h$,} \\
      u_h = g_h &\text{ auf $\partial \Omega_h$}
    \end{array} \right. \\
    \text{(LGS)} \enspace & \tilde{\LL}_h \tilde{u}_h = \tilde{f}_h
  \end{align*}
\end{ziel}

\begin{nota}
  %Sei $U_h$ der Raum aller Funktionen mit Werten in $\R$, die auf dem Gitter $\Omega_h$ definiert sind und sei  die Einschränkung stetiger Funktionen auf $\Omega_h$. \\
  $U_h \coloneqq \{ \Omega_h \to \R \}$, \quad
  $R_h : \Cont(\cOmega) \to U_h, \enspace u \mapsto u|_{\Omega_h}$
\end{nota}

\begin{defn}
  Das Differenzenverfahren (RWP)\tss{h} heißt
  \begin{itemize}
    \item \emph{konvergent} von der Ordnung~$p$, falls $C > 0$, $h_0 > 0$ existieren, sodass für die Lösung~$u$ von (RWP) und die Lösung~$u_h$ von (RWP)\tss{h} gilt:
    \[
      \norm{u_h - R_h u}_h \leq C h^p \quad
      \text{für alle $0 < h \leq h_0$,}
    \]
    wobei~$\norm{\blank}_h$ eine Norm zu~$U_h$ ist, wie \zB{} $\norm{u_h}_h \coloneqq \max_{x \in \Omega_h} \abs{u_h(x)}$.
    \item \emph{konsistent} von der Ordnung~$p$, falls
    \[
      \norm{\LL_h R_h u - R_h \LL u}_h \leq c h^p \norm{u}_{\Cont^{p+2}(\cOmega)} \quad
      \forall u \in \Cont^{p+2}(\cOmega).
    \]
    % Falls u eine Lösung von (RWP) ist, so gilt
    %\[ \LL_h R_h u - R_h \LL u = \LL_h R_h u - R_h f = \LL_h u - f_h \]
    \item \emph{stabil}, falls $\tilde{L}_h$ invertierbar ist und ein $h_0 > 0$ existiert mit
    \[
      \sup_{0 < h \leq h_0} \norm{\tilde{\LL}_h^{-1}}_h < \infty, \quad
      \text{wobei} \enspace
      \norm{\tilde{\LL}_h^{-1}}_h \coloneqq \sup_{f \neq 0} \tfrac{\norm{\tilde{\LL}^{-1}_h f}_h}{\norm{f}_h}.
    \]
  \end{itemize}
\end{defn}

\begin{bem}
  Die ind. Matrixnorm ist $\norm{\tilde{\LL}_h^{-1}}_h = \norm{\tilde{\LL}_h^{-1}}_\infty = \max_{1 \leq i \leq n} \sum_{j=1}^n \abs{l_{ij}}$.
\end{bem}

% Was ist das Residuum??? Was heißt Konditionierung eines Problems?

% 3.1
\begin{satz}
  Ist das DV (RWP)\tss{h} konsistent und stabil, so auch konvergent.
  Genauer gilt: Ist (RWP)\tss{h} stabil und konsistent von der Ordnung~$p$ und $u \in \Cont^{p+2}(\cOmega)$, dann ist (RWP)\tss{h} konvergent von der Ordnung~$p$.
\end{satz}

% Was ist Spalten-, Spektrale und Zeilensummennorm?
% Spa-Spe-Zei

\begin{proof}
  Setze $w_h \coloneqq u_h - R_h u$.
  Für $x \in \partial \Omega_h$ gilt dann $w_h(x) = 0$ und für $x \in \Omega_h$ gilt
  \begin{align*}
    \tilde{\LL}_h w_h(x) &= \LL_h w_h(x) = \LL_h u_h(x) - \LL_h R_h u(x) \\
    &= f_h(x) - \LL_h R_h u(x) = R_h f(x) - \LL_h R_h u(x) \\
    &= R_h \LL u(x) - \LL_h R_h u(x)
  \end{align*}
  Somit gilt $w_h = \tilde{\LL}_h^{-1} \left( R_h \LL u - \LL_h R_h u \right)$ in $\Omega_h$, also
  \begin{align*}
    \norm{w_h}_h &= \norm{\tilde{\LL}_h^{-1} \left( R_h \LL u - \LL_h R_h u \right)}
    \leq \norm{\tilde{\LL}_h^{-1}}_h \cdot \norm{R_h \LL u - \LL_h R_h u}_h \\
    & \leq c_1 \cdot c_2 \cdot h^p \cdot \norm{u}_{\Cont^{p+2}(\cOmega)}
    \leq C h^p \qquad
    \text{für $0 < h \leq h_0$.} \qedhere
  \end{align*}
\end{proof}

% 3.2
\begin{lem}
  Das DV (RWP\tss{1})\tss{h} ist konsistent von der Ordnung 2.
  Es gilt
  \[
    \norm{\Laplace_h R_h u - R_h \Laplace u}_h \leq \tfrac{1}{12} \norm{u}_{\Cont^4(\cOmega)} h^2 \quad
    \forall u \in \Cont^4(\cOmega).
  \]
\end{lem}

% Beweis ähnlich wie auf ÜB2 mit Taylorn

\begin{bem}
  Um zu zeigen, dass (RWP\tss{1})\tss{h} konvergent ist, müssen wir noch zeigen, dass $\tilde{L}_h = - \tilde{\Laplace}_h$ invertierbar ist und $\sup_{0 < h \leq h_0} \norm{\tilde{\Laplace}_h} < \infty$.
\end{bem}

\begin{defn}
  Eine Matrix $A = (a_{ij}) \in \R^{n \times n}$ heißt \emph{M-Matrix}, falls
  \begin{itemize}
    \miniitem{0.43 \linewidth}{$a_{ii} > 0$ für $i = 1, \ldots, n$,}
    \miniitem{0.53 \linewidth}{$a_{ij} \leq 0$ für $i \neq j$, $i, j = 1, \ldots, n$,}
    \miniitem{0.43 \linewidth}{$A$ invertierbar ist und}
    \miniitem{0.53 \linewidth}{für $A^{-1} =: B = (b_{ij})$ gilt $b_{ij} \geq 0$.}
  \end{itemize}
\end{defn}

\begin{bem}
  Es gilt folgende Monotonie-Eigenschaft für M-Matrizen:
  \[
    x \leq y \implies
    A^{-1} x \leq A^{-1} y.
  \]
  % je komponentenweise
\end{bem}

\begin{defn}
  Sei $A = (a_{ij}) \in \R^{n \times n}$ eine Matrix.
  \begin{itemize}
    \item $A$ heißt \emph{schwach diagonaldominant}, falls
    \[
      \sum_{\substack{j=1\\j \neq i}}^n \abs{a_{ij}} \leq \abs{a_{ii}} \quad
      \text{für $i = 1, \ldots, n$}
    \]
    und ein $i_0$ existiert, sodass die Ungleichung strikt ist.
    \item $A$ heißt \emph{diagonaldominant}, falls
    \[
      \sum_{\substack{j=1\\j \neq i}}^n \abs{a_{ij}} < \abs{a_{ii}} \quad
      \text{für $i = 1, \ldots, n$}
    \]
  \end{itemize}
\end{defn}

\begin{bem}
  $- \tilde{\Laplace}_h$ ist schwach diagonaldominant
\end{bem}

\begin{defn}
  Eine Matrix $A \in \R^{n \times n}$ heißt \emph{reduzibel} (oder zerlegbar), wenn es eine Permutationsmatrix $P \in \R^{n \times n}$ gibt, sodass
  \[
    PAP^T = \begin{psmallmatrix}
      A_{11} & A_{12} \\
      0 & A_{22}
    \end{psmallmatrix} \quad
    \text{mit $A_{11} \in R^{k \times k}$, $0 < k < n$.}
  \]
  % Ist $A$ nicht redzibel, so heißt $A$ irreduzibel
\end{defn}

% Ausgelassen: Beispiel einer reduziblen Matrix

% Vorlesung vom 27.10.2015

\begin{defn}
  Eine $(n \times n)$-Matrix heißt \emph{irreduzibel diagonaldominant}, falls sie irreduzibel und schwach diagonaldominant ist.
\end{defn}

% 3.3
\begin{lem}
  Sei $A = (a_{ij}) \in \R^{n \times n}$ eine Matrix mit $a_{ii} > 0$, $i = 1, \ldots, n$ und $a_{ij} \leq 0$, $i, j = 1, \ldots, n$, $i \neq j$, die diagonaldominant oder irreduzibel diagonaldominant ist.
  Dann ist $A$ eine M-Matrix.
\end{lem}

\begin{bem}
  $- \tilde{\Laplace}_h$ ist irreduzibel diagonaldominant, also eine M-Matrix.
\end{bem}

% Noch zu zeigen: $\sup_{0 < h \leq h_0} \norm{\tilde{\Laplace}_h^{-1}} < \infty$

% 3.4
\begin{lem}
  Sei $A \in \R^{n \times n}$ eine M-Matrix und es existiere ein Vektor $v$, sodass $(Av)_j \geq 1$, $j = 1, \ldots, n$.
  Dann gilt $\norm{A^{-1}}_\infty \leq \norm{v}_\infty$.
\end{lem}

% 3.5
\begin{lem}
  $\norm{\tilde{\Laplace}_h^{-1}}_\infty \leq \tfrac{1}{8}$
\end{lem}

% Beweis folgt aus dem letzten Lemma mit $v = (v_1, \ldots, v_n)^T$ mit $v_i \coloneqq h^2/2 i (n-i)$

% 3.6
\begin{satz}
  Das DV (RWP\tss{1})\tss{h} ist konvergent von der Ordnung 2, falls die Lösung von (RWP\tss{1}) zu $\Cont^4(\cinterval{0}{1})$ gehört.
  Es gilt die Abschätzung $\norm{u_h - R_h u}_\infty \leq \tfrac{h^2}{96} \norm{u}_{\Cont^4(\cinterval{0}{1})}$.
\end{satz}

% 3.2. Differenzenverfahren für die Poisson-Gleichung in $\Omega = \ointerval{0}{1} \times \ointerval{0}{1}$

\begin{problem}
  Wir betrachten nun
  \[
    \text{(RWP\tss{2})} \left\{ \begin{array}{rlll}
      - \Laplace u &=& f &\text{ in $\Omega = \ointerval{0}{1} \times \ointerval{0}{1}$} \\
      u &=& g &\text{ auf $\bOmega$}
    \end{array} \right.
  \]
\end{problem}

\begin{enumerate}
  \item Diskretisierung: Setze $h \coloneqq \tfrac{1}{n}$, $n \in \N$ und
  \begin{align*}
    \Omega_h & \coloneqq \Set{(x, y) \in \Omega}{x = ih, y = jh, i,j = 1, \ldots, {n-1}} \\
    \partial \Omega_h & \coloneqq \Set{(x, y) \in \bOmega}{x = ih, y = jh, i,j = 1, \ldots, {n-1}}
  \end{align*}
  \item Approximation der Ableitungen
  \begin{align*}
  - \Laplace u (x, y)
  &= - \tfrac{\partial^2 u}{\partial x^2} (x,y) - \tfrac{\partial^2 u}{\partial y^2} (x, y) \\
  &\approx - \tfrac{u(x + h, y) - 2 u(x, y) + u(x-h, y)}{h^2} - \tfrac{u(x, y+h) - 2 u(x,y) + u(x, y-h)}{h^2} \\
  &= - \tfrac{u(x+h,y) + u(x-h,y) - 4 u(x, y) + u(x, y+h) + u(x, y-h)}{h^2} =: - \Laplace_h u
  \end{align*}
  Dabei hat der diskrete Laplace-Operator $\Laplace_h$ die Form eines Differenzensterns.
  Gesucht ist die Lsg $u_h : \Omega_h \cup \partial \Omega_h \to \R$ von
  \[
    \text{(RWP\tss{2})\tss{h}} \left\{ \begin{array}{rlll}
      - \Laplace_h u_h &=& f_h &\text{ in $\Omega_h$} \\
      u_h &=& g &\text{ auf $\bOmega_h$.}
    \end{array} \right.
  \]
  \item Aufstellen des linearen Gleichungssystems $- \tilde{\Laplace}_h \tilde{u}_h = f_h$:
  % wir verwenden hier die zeilenweise Nummerierung
  \[
    \tilde{u}_h = \begin{pmatrix}
      u_{11} \\
      u_{12} \\
      \vdots \\
      u_{n-1,n-2} \\
      u_{n-1,n-1}
    \end{pmatrix} \in \R^{(n-1)^2},
  \]
  \begin{align*}
    - \tilde{\Laplace}_h = \frac{1}{h^2} & \begin{pmatrix}
      A & -I & && 0 \\
      -I & A & -I && \\
      & \ddots & \ddots & \ddots \\
      && -I & A & -I \\
      0 &&& -I & A
    \end{pmatrix} \in \R^{(n-1)^2 \times (n-1)^2}, \\
    A = & \begin{pmatrix}
      4 & -1 & && 0 \\
      -1 & 4 & -1 && \\
      & \ddots & \ddots & \ddots \\
      && -1 & 4 & -1 \\
      0 &&& -1 & 4
    \end{pmatrix} \in \R^{n-1 \times n-1}
  \end{align*}
\end{enumerate}

% Vorlesung vom 2.11.2015

% 3.7
\begin{lem}
  Das DV (RWP\tss{2})\tss{h} ist konsistent von der Ordnung 2.
  Es gilt
  \[ \norm{\Laplace_h R_h u - R_h \Laplace u}_h \leq \tfrac{1}{6} \norm{u}_{\Cont^r(\cOmega)} h^2. \]
\end{lem}

% 3.8
\begin{lem}
  Das DV (RWP\tss{2})\tss{h} ist stabil.
  Es gilt $\norm{\tilde{D}_h^{-1}}_\infty \leq \nicefrac{1}{8}$.
\end{lem}

% Begründung: $-\tilde{\Laplace}_h$ ist eine M-Matrix, da schwach diagonaldominant und irreduzibel

% 3.9
\begin{satz}
  Das DV (RWP\tss{2})\tss{h} ist konvergent von der Ordnung 2, falls die Lösung von (RWP\tss{2}) zu $\Cont^4(\cOmega)$ gehört.
  Es gilt
  \[ \norm{u_h - R_h u}_h \leq \nicefrac{1}{48} \norm{u} \]
\end{satz}

\begin{bem}
  Durch die Einbeziehung weiterer Gitterpunkte zur Approximation des Differentialoperators lässt sich die Konvergenzordnung erhöhen:
  % Dies geht mit dem 9-Punkte-Stern
  %             1
  %             |
  %            -16
  %             |
  % 1 -- -16 -- 60 -- -16 -- 1
  %             |
  %            -16
  %             |
  %             1
  \begin{align*}
    - \Laplace_h^{(9)} & u(x, y) = \tfrac{1}{12 h^2} \left( u(x{-}2h, y) - 16 u(x{-}h, y) + 30 u(x, y) \right. \\
    & \left. - 16 u(x{+}h, y) + u(x{+}2h, y) + u(x, y{-}2h) - 16 u(x, y{-}h) \right. \\
    & \left. + 30 u(x, y) - 16 u(x, y{+}h) + u(x, y{+}2h) \right) \approx - \Laplace u(x, y)
  \end{align*}
  Damit erreicht man die Konsistenzordnung 4.
  % oder:
  % -1/3  -1/3  -1/3
  % -1/3   8/3  -1/3
  % -1/3  -1/3  -1/3
  % Die Erweiterung auf nichtrechteckige Gebiete ist trivial
\end{bem}

% 3.3. Diskretisierung in einem beschränkten Gebiet in R^2

Sei $\Omega \subset \R^2$ beschränkt, $\Omega_h = \Set{x, y \in \Omega}{\nicefrac{x}{h}, \nicefrac{y}{h} \in \Z}$ % Menge der inneren Gitterpunkte

\begin{defn}
  \begin{itemize}
    \item Ein Punkt $z_R \in \bOmega$ heißt \emph{Randgitterpunkt}, falls es einen inneren Gitterpunkt $z \in \Omega_h$ gibt, sodass $z_R = r + \alpha h e_1$ oder $z_R = z + \alpha h e_2$ mit $\abs{\alpha} \leq 1$.
    \item Ein Punkt $(x, y) \in \Omega_h$ heißt \emph{randnah}, falls $(x, y)$ die Nachbarn $(x - s_l h, y)$, $(x + s_r h, y)$, $(x, y - s_u h)$, $(x, y+ s_o h)$ hat mit mindestens einem $s_i < 1$.
    Ansonsten heißt $(x, y)$ \emph{randfern}.
  \end{itemize}
\end{defn}

Wir haben eine Einteilung $\Omega_h = \Omega_h^\rn \sqcup \Omega_h^\rf$ der Gitterpunkte in randnahe und randferne Punkte.

% TODO: Zeichung

% 3.3.1 Shortley-Weller-Diskretisierung

Dividierte Differenzen von Newton:

Sei $u \in \Cont^3(\cinterval{x_l}{x_r})$.

\begin{align*}
  u''(x) & = \frac{2}{x_r - x_l} \left( \frac{u(x_r) - u(x)}{x_r - x} - \frac{u(x) - u(x_l)}{x - x_l} \right) + \vartheta(x_r - x_l) \\
  & = \frac{2}{x_r - x_l} \left( \frac{1}{x_r - x} u(x_r) + \frac{1}{x - x_l} u(x_l) \right) - \frac{2}{(x_r - x)(x - x_l)} u(x) + \vartheta(x_r - x_l)
\end{align*}

\[
  \mathcal{D}_h u(x, y) = \nicefrac{1}{h^2} \left( \frac{2}{s_l (s_r + s_l)} u(x - s_l h, y) + \frac{2}{s_r (s_r + s_l)} u(x+s_r h, y) + \frac{2}{s_u (s_o + s_u)} u(x, y - s_u h) + \frac{2}{s_o (s_o + s_u)} u(x, y + s_o h) - (\frac{2}{s_l s_r} + \frac{2}{s_o s_u}) u(x, y) \right)
\]

$x_r - x_l = (s_r + s_l) h$

$x_r - x =  s_r h$

$x - x_l = s_l h$

$y_o - y_u = (s_o - s_u) h$

$y_o - y = s_o h$

$y - y_u = s_u h$

\end{document}